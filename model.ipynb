{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b52e5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a43a91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_formats(date):\n",
    "    for fmt in ('%m/%d/%Y', '%m-%d-%Y'):\n",
    "        try:\n",
    "            return pd.to_datetime(date, format=fmt)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return pd.NaT\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"gingers.csv\")\n",
    "df2 = pd.read_csv(\"climate.csv\")\n",
    "\n",
    "df.dropna(subset=['Date'], inplace=True)\n",
    "df['Date'] = pd.to_datetime(df['Date'], dayfirst=True)\n",
    "df.set_index('Date', inplace=True)\n",
    "df = df.resample('D').asfreq()\n",
    "df = df.interpolate(method='linear')\n",
    "\n",
    "df2['Date'] = df2['Date'].apply(try_formats)\n",
    "df2.dropna(subset=['Date'], inplace=True)  # Drop rows with NaT in 'Date'\n",
    "\n",
    "df2.set_index('Date', inplace=True)\n",
    "df2 = df2.resample('D').asfreq()\n",
    "df2 = df2.interpolate(method='linear')\n",
    "\n",
    "time = np.arange(len(df), dtype=\"float32\")\n",
    "series=df[\"Average\"]\n",
    "climate=df2[\"QV2M\"]\n",
    "print(df.shape,df2.shape)\n",
    "df.head(20)\n",
    "df2.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efabc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(series)\n",
    "print(climate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd90b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(time,series)\n",
    "plt.show()\n",
    "print(len(series),len(climate))\n",
    "plt.plot(time,climate)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2084d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_series(time, series, format=\"-\", start=0, end=None):\n",
    "    \"\"\"\n",
    "    Visualizes time series data\n",
    "\n",
    "    Args:\n",
    "      time (array of int) - contains the time steps\n",
    "      series (array of int) - contains the measurements for each time step\n",
    "      format - line style when plotting the graph\n",
    "      start - first time step to plot\n",
    "      end - last time step to plot\n",
    "    \"\"\"\n",
    "\n",
    "    # Setup dimensions of the graph figure\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    if type(series) is tuple:\n",
    "\n",
    "      for series_num in series:\n",
    "        # Plot the time series data\n",
    "        plt.plot(time[start:end], series_num[start:end], format)\n",
    "\n",
    "    else:\n",
    "      # Plot the time series data\n",
    "      plt.plot(time[start:end], series[start:end], format)\n",
    "\n",
    "    # Label the x-axis\n",
    "    plt.xlabel(\"Time\")\n",
    "\n",
    "    # Label the y-axis\n",
    "    plt.ylabel(\"Value\")\n",
    "\n",
    "    # Overlay a grid on the graph\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Draw the graph on screen\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e657a02",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_series(time, series)\n",
    "plot_series(time, climate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d56d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the split time\n",
    "split_time = 2000\n",
    "\n",
    "# Get the train set\n",
    "time_train = time[:split_time]\n",
    "x1_train = series[:split_time]\n",
    "x2_train=climate[:split_time]\n",
    "\n",
    "print(len(x1_train),len(x2_train))\n",
    "# Get the validation set\n",
    "time_valid = time[split_time:]\n",
    "x1_valid = series[split_time:]\n",
    "x2_=climate[split_time:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ad5aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "window_size = 20\n",
    "batch_size = 2\n",
    "shuffle_buffer_size = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1d51cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_windowed_dataset(series1, series2, window_size, batch_size):\n",
    "    series1 = np.array(series1)  # Convert to NumPy array\n",
    "    series2 = np.array(series2)  # Convert to NumPy array\n",
    "\n",
    "    data = []\n",
    "    labels = []\n",
    "    for i in range(len(series1) - window_size):\n",
    "        window = series1[i:i + window_size], series2[i:i + window_size]\n",
    "        label = series1[i + window_size] \n",
    "        window = np.concatenate(window)\n",
    "        label = np.array([label])\n",
    "        data.append(window)\n",
    "        labels.append(label)\n",
    "    data = np.array(data)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    data = tf.convert_to_tensor(data)\n",
    "    labels = tf.convert_to_tensor(labels)\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "    dataset = dataset.shuffle(len(data)).batch(batch_size).prefetch(1)\n",
    "    return dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b52ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_windowed_dataset(x1_train, x2_train, window_size, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e063316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print shapes of feature and label\n",
    "for window in dataset.take(1):\n",
    "  print(f'shape of feature: {window[0].shape}')\n",
    "  print(f'shape of label: {window[1].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5388b5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_forecast(model, series, window_size, batch_size):\n",
    "    \"\"\"Uses an input model to generate predictions on data windows\n",
    "\n",
    "    Args:\n",
    "      model (TF Keras Model) - model that accepts data windows\n",
    "      series (array of float) - contains the values of the time series \n",
    "      window_size (int) - the number of time steps to include in the window\n",
    "      batch_size (int) - the batch size\n",
    "\n",
    "    Returns:\n",
    "      forecast (numpy array) - array containing predictions\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate a TF Dataset from the series values\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
    "\n",
    "    # Window the data but only take those with the specified size\n",
    "    dataset = dataset.window(window_size, shift=1, drop_remainder=True)\n",
    "\n",
    "    # Flatten the windows by putting its elements in a single batch\n",
    "    dataset = dataset.flat_map(lambda w: w.batch(window_size))\n",
    "\n",
    "    # Create batches of windows\n",
    "    dataset = dataset.batch(batch_size).prefetch(1)\n",
    "\n",
    "    # Get predictions on the entire dataset\n",
    "    forecast = model.predict(dataset)\n",
    "\n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6203665d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model_simplernn = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),\n",
    "                      input_shape=[window_size]),\n",
    "  tf.keras.layers.SimpleRNN(25, return_sequences=True,activation=\"ReLU\"),\n",
    "  tf.keras.layers.SimpleRNN(15,activation=\"ReLU\"),\n",
    "  tf.keras.layers.Dense(1,activation=\"linear\"),\n",
    "])\n",
    "\n",
    "# Set the optimizer\n",
    "\n",
    "# Set the training parameters\n",
    "model_simplernn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),loss=tf.keras.losses.MeanSquaredError(),\n",
    "              metrics=[\"mse\"])\n",
    "\n",
    "# Train the model\n",
    "history = model_simplernn.fit(dataset,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaff805",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_series = series[:-1]\n",
    "print(len(forecast_series))\n",
    "forecast = model_forecast(model_simplernn, forecast_series, window_size, batch_size)\n",
    "results = forecast.squeeze()\n",
    "print(series[window_size:].shape[0],results.shape[0],time[window_size:].shape[0])\n",
    "plt.plot(time[window_size:],series[window_size:])\n",
    "plt.show()\n",
    "plot_series(time[window_size:], (series[window_size:], results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242f2182",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_series = series[split_time - window_size:-1]\n",
    "forecast = model_forecast(model_simplernn, forecast_series, window_size, batch_size)\n",
    "\n",
    "# Drop single dimensional axis\n",
    "results = forecast.squeeze()\n",
    "\n",
    "# Plot the results\n",
    "plot_series(time_valid, (x1_valid, results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d21f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model_gru = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),\n",
    "                      input_shape=[window_size]),\n",
    "  tf.keras.layers.GRU(25, return_sequences=True,activation=\"ReLU\"),\n",
    "  tf.keras.layers.GRU(15,activation=\"ReLU\"),\n",
    "  tf.keras.layers.Dense(1,activation=\"linear\"),\n",
    "])\n",
    "\n",
    "# Set the optimizer\n",
    "\n",
    "# Set the training parameters\n",
    "model_gru.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),loss=tf.keras.losses.MeanSquaredError(),\n",
    "              metrics=[\"mse\"])\n",
    "\n",
    "# Train the model\n",
    "history = model_gru.fit(dataset,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5469f05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_series = series[:-1]\n",
    "print(len(forecast_series))\n",
    "forecast = model_forecast(model_gru, forecast_series, window_size, batch_size)\n",
    "results = forecast.squeeze()\n",
    "print(series[window_size:].shape[0],results.shape[0],time[window_size:].shape[0])\n",
    "plt.plot(time[window_size:],series[window_size:])\n",
    "plt.show()\n",
    "plot_series(time[window_size:], (series[window_size:], results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff54a1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_series = series[split_time - window_size:-1]\n",
    "forecast = model_forecast(model_gru, forecast_series, window_size, batch_size)\n",
    "\n",
    "# Drop single dimensional axis\n",
    "results = forecast.squeeze()\n",
    "\n",
    "# Plot the results\n",
    "plot_series(time_valid, (x1_valid, results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094ddcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model_lstm = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),\n",
    "                      input_shape=[window_size]),\n",
    "  tf.keras.layers.LSTM(25, return_sequences=True,activation=\"ReLU\"),\n",
    "  tf.keras.layers.LSTM(15,activation=\"ReLU\"),\n",
    "  tf.keras.layers.Dense(1,activation=\"ReLU\"),\n",
    "])\n",
    "\n",
    "# Set the optimizer\n",
    "\n",
    "# Set the training parameters\n",
    "model_lstm.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),loss=tf.keras.losses.MeanSquaredError(),\n",
    "              metrics=[\"mse\"])\n",
    "\n",
    "# Train the model\n",
    "history = model_lstm.fit(dataset,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216aef22",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_series = series[:-1]\n",
    "print(len(forecast_series))\n",
    "forecast = model_forecast(model_lstm, forecast_series, window_size, batch_size)\n",
    "results = forecast.squeeze()\n",
    "print(series[window_size:].shape[0],results.shape[0],time[window_size:].shape[0])\n",
    "plt.plot(time[window_size:],series[window_size:])\n",
    "plt.show()\n",
    "plot_series(time[window_size:], (series[window_size:], results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6f4313",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_series = series[split_time - window_size:-1]\n",
    "forecast = model_forecast(model_lstm, forecast_series, window_size, batch_size)\n",
    "\n",
    "# Drop single dimensional axis\n",
    "results = forecast.squeeze()\n",
    "\n",
    "# Plot the results\n",
    "plot_series(time_valid, (x1_valid, results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
